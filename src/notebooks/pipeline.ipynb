{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/y.kotani/Desktop/study/youtube_predict_view_count/.venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/y.kotani/Desktop/study/youtube_predict_view_count/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from lib.repository.load_data import YoutubeVideoDataRepository\n",
    "from lib.service.data import YoutubeVideoDataService\n",
    "from lib.pipeline.feature import FeatureExtractionPipeline\n",
    "from lib.pipeline.training import TraingingPipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2data = \"/Users/y.kotani/Downloads/30分以内に投稿された動画データ.xlsx\"\n",
    "repository = YoutubeVideoDataRepository(path2data=path2data)\n",
    "service = YoutubeVideoDataService(repository=repository)\n",
    "\n",
    "transformed_data = service.get_transformed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FeatureExtractionPipeline(\n",
    "    original_df=transformed_data,\n",
    ")\n",
    "feature_extraxted_data = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extraxted_data.to_csv(\"../data/feature_extraxted_data.csv\", index=False)\n",
    "feature_extraxted_data = pd.read_csv(\"../data/feature_extraxted_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['minutes_diff', 'sin_hour', 'cos_hour', 'day_of_week_str_Friday', 'day_of_week_str_Monday', 'day_of_week_str_Saturday', 'day_of_week_str_Sunday', 'day_of_week_str_Thursday', 'day_of_week_str_Tuesday', 'day_of_week_str_Wednesday', 'comment_count', 'like_count', 'favorite_count', 'duration_min', 'subscriber_count', 'text_embeddings_0', 'text_embeddings_1', 'text_embeddings_2', 'text_embeddings_3', 'text_embeddings_4', 'text_embeddings_5', 'text_embeddings_6', 'text_embeddings_7', 'text_embeddings_8', 'text_embeddings_9', 'text_embeddings_10', 'text_embeddings_11', 'text_embeddings_12', 'text_embeddings_13', 'text_embeddings_14', 'text_embeddings_15', 'text_embeddings_16', 'text_embeddings_17', 'text_embeddings_18', 'text_embeddings_19', 'text_embeddings_20', 'text_embeddings_21', 'text_embeddings_22', 'text_embeddings_23', 'text_embeddings_24', 'text_embeddings_25', 'text_embeddings_26', 'text_embeddings_27', 'text_embeddings_28', 'text_embeddings_29', 'text_embeddings_30', 'text_embeddings_31', 'text_embeddings_32', 'text_embeddings_33', 'text_embeddings_34', 'text_embeddings_35', 'text_embeddings_36', 'text_embeddings_37', 'text_embeddings_38', 'text_embeddings_39', 'text_embeddings_40', 'text_embeddings_41', 'text_embeddings_42', 'text_embeddings_43', 'text_embeddings_44', 'text_embeddings_45', 'text_embeddings_46', 'text_embeddings_47', 'text_embeddings_48', 'text_embeddings_49', 'text_embeddings_50', 'text_embeddings_51', 'text_embeddings_52', 'text_embeddings_53', 'text_embeddings_54', 'text_embeddings_55', 'text_embeddings_56', 'text_embeddings_57', 'text_embeddings_58', 'text_embeddings_59', 'text_embeddings_60', 'text_embeddings_61', 'text_embeddings_62', 'text_embeddings_63', 'text_embeddings_64', 'text_embeddings_65', 'text_embeddings_66', 'text_embeddings_67', 'text_embeddings_68', 'text_embeddings_69', 'text_embeddings_70', 'text_embeddings_71', 'text_embeddings_72', 'text_embeddings_73', 'text_embeddings_74', 'text_embeddings_75', 'text_embeddings_76', 'text_embeddings_77', 'text_embeddings_78', 'text_embeddings_79', 'text_embeddings_80', 'text_embeddings_81', 'text_embeddings_82', 'text_embeddings_83', 'text_embeddings_84', 'text_embeddings_85', 'text_embeddings_86', 'text_embeddings_87', 'text_embeddings_88', 'text_embeddings_89', 'text_embeddings_90', 'text_embeddings_91', 'text_embeddings_92', 'text_embeddings_93', 'text_embeddings_94', 'text_embeddings_95', 'text_embeddings_96', 'text_embeddings_97', 'text_embeddings_98', 'text_embeddings_99', 'text_embeddings_100', 'text_embeddings_101', 'text_embeddings_102', 'text_embeddings_103', 'text_embeddings_104', 'text_embeddings_105', 'text_embeddings_106', 'text_embeddings_107', 'text_embeddings_108', 'text_embeddings_109', 'text_embeddings_110', 'text_embeddings_111', 'text_embeddings_112', 'text_embeddings_113', 'text_embeddings_114', 'text_embeddings_115', 'text_embeddings_116', 'text_embeddings_117', 'text_embeddings_118', 'text_embeddings_119', 'text_embeddings_120', 'text_embeddings_121', 'text_embeddings_122', 'text_embeddings_123', 'text_embeddings_124', 'text_embeddings_125', 'text_embeddings_126', 'text_embeddings_127', 'text_embeddings_128', 'text_embeddings_129', 'text_embeddings_130', 'text_embeddings_131', 'text_embeddings_132', 'text_embeddings_133', 'text_embeddings_134', 'text_embeddings_135', 'text_embeddings_136', 'text_embeddings_137', 'text_embeddings_138', 'text_embeddings_139', 'text_embeddings_140', 'text_embeddings_141', 'text_embeddings_142', 'text_embeddings_143', 'text_embeddings_144', 'text_embeddings_145', 'text_embeddings_146', 'text_embeddings_147', 'text_embeddings_148', 'text_embeddings_149', 'text_embeddings_150', 'text_embeddings_151', 'text_embeddings_152', 'text_embeddings_153', 'text_embeddings_154', 'text_embeddings_155', 'text_embeddings_156', 'text_embeddings_157', 'text_embeddings_158', 'text_embeddings_159', 'text_embeddings_160', 'text_embeddings_161', 'text_embeddings_162', 'text_embeddings_163', 'text_embeddings_164', 'text_embeddings_165', 'text_embeddings_166', 'text_embeddings_167', 'text_embeddings_168', 'text_embeddings_169', 'text_embeddings_170', 'text_embeddings_171', 'text_embeddings_172', 'text_embeddings_173', 'text_embeddings_174', 'text_embeddings_175', 'text_embeddings_176', 'text_embeddings_177', 'text_embeddings_178', 'text_embeddings_179', 'text_embeddings_180', 'text_embeddings_181', 'text_embeddings_182', 'text_embeddings_183', 'text_embeddings_184', 'text_embeddings_185', 'text_embeddings_186', 'text_embeddings_187', 'text_embeddings_188', 'text_embeddings_189', 'text_embeddings_190', 'text_embeddings_191', 'text_embeddings_192', 'text_embeddings_193', 'text_embeddings_194', 'text_embeddings_195', 'text_embeddings_196', 'text_embeddings_197', 'text_embeddings_198', 'text_embeddings_199', 'text_embeddings_200', 'text_embeddings_201', 'text_embeddings_202', 'text_embeddings_203', 'text_embeddings_204', 'text_embeddings_205', 'text_embeddings_206', 'text_embeddings_207', 'text_embeddings_208', 'text_embeddings_209', 'text_embeddings_210', 'text_embeddings_211', 'text_embeddings_212', 'text_embeddings_213', 'text_embeddings_214', 'text_embeddings_215', 'text_embeddings_216', 'text_embeddings_217', 'text_embeddings_218', 'text_embeddings_219', 'text_embeddings_220', 'text_embeddings_221', 'text_embeddings_222', 'text_embeddings_223', 'text_embeddings_224', 'text_embeddings_225', 'text_embeddings_226', 'text_embeddings_227', 'text_embeddings_228', 'text_embeddings_229', 'text_embeddings_230', 'text_embeddings_231', 'text_embeddings_232', 'text_embeddings_233', 'text_embeddings_234', 'text_embeddings_235', 'text_embeddings_236', 'text_embeddings_237', 'text_embeddings_238', 'text_embeddings_239', 'text_embeddings_240', 'text_embeddings_241', 'text_embeddings_242', 'text_embeddings_243', 'text_embeddings_244', 'text_embeddings_245', 'text_embeddings_246', 'text_embeddings_247', 'text_embeddings_248', 'text_embeddings_249', 'text_embeddings_250', 'text_embeddings_251', 'text_embeddings_252', 'text_embeddings_253', 'text_embeddings_254', 'text_embeddings_255', 'text_embeddings_256', 'text_embeddings_257', 'text_embeddings_258', 'text_embeddings_259', 'text_embeddings_260', 'text_embeddings_261', 'text_embeddings_262', 'text_embeddings_263', 'text_embeddings_264', 'text_embeddings_265', 'text_embeddings_266', 'text_embeddings_267', 'text_embeddings_268', 'text_embeddings_269', 'text_embeddings_270', 'text_embeddings_271', 'text_embeddings_272', 'text_embeddings_273', 'text_embeddings_274', 'text_embeddings_275', 'text_embeddings_276', 'text_embeddings_277', 'text_embeddings_278', 'text_embeddings_279', 'text_embeddings_280', 'text_embeddings_281', 'text_embeddings_282', 'text_embeddings_283', 'text_embeddings_284', 'text_embeddings_285', 'text_embeddings_286', 'text_embeddings_287', 'text_embeddings_288', 'text_embeddings_289', 'text_embeddings_290', 'text_embeddings_291', 'text_embeddings_292', 'text_embeddings_293', 'text_embeddings_294', 'text_embeddings_295', 'text_embeddings_296', 'text_embeddings_297', 'text_embeddings_298', 'text_embeddings_299', 'text_embeddings_300', 'text_embeddings_301', 'text_embeddings_302', 'text_embeddings_303', 'text_embeddings_304', 'text_embeddings_305', 'text_embeddings_306', 'text_embeddings_307', 'text_embeddings_308', 'text_embeddings_309', 'text_embeddings_310', 'text_embeddings_311', 'text_embeddings_312', 'text_embeddings_313', 'text_embeddings_314', 'text_embeddings_315', 'text_embeddings_316', 'text_embeddings_317', 'text_embeddings_318', 'text_embeddings_319', 'text_embeddings_320', 'text_embeddings_321', 'text_embeddings_322', 'text_embeddings_323', 'text_embeddings_324', 'text_embeddings_325', 'text_embeddings_326', 'text_embeddings_327', 'text_embeddings_328', 'text_embeddings_329', 'text_embeddings_330', 'text_embeddings_331', 'text_embeddings_332', 'text_embeddings_333', 'text_embeddings_334', 'text_embeddings_335', 'text_embeddings_336', 'text_embeddings_337', 'text_embeddings_338', 'text_embeddings_339', 'text_embeddings_340', 'text_embeddings_341', 'text_embeddings_342', 'text_embeddings_343', 'text_embeddings_344', 'text_embeddings_345', 'text_embeddings_346', 'text_embeddings_347', 'text_embeddings_348', 'text_embeddings_349', 'text_embeddings_350', 'text_embeddings_351', 'text_embeddings_352', 'text_embeddings_353', 'text_embeddings_354', 'text_embeddings_355', 'text_embeddings_356', 'text_embeddings_357', 'text_embeddings_358', 'text_embeddings_359', 'text_embeddings_360', 'text_embeddings_361', 'text_embeddings_362', 'text_embeddings_363', 'text_embeddings_364', 'text_embeddings_365', 'text_embeddings_366', 'text_embeddings_367', 'text_embeddings_368', 'text_embeddings_369', 'text_embeddings_370', 'text_embeddings_371', 'text_embeddings_372', 'text_embeddings_373', 'text_embeddings_374', 'text_embeddings_375', 'text_embeddings_376', 'text_embeddings_377', 'text_embeddings_378', 'text_embeddings_379', 'text_embeddings_380', 'text_embeddings_381', 'text_embeddings_382', 'text_embeddings_383']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 11440, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 15798.805857\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's rmse: 13978\tvalid_1's rmse: 31540.1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 11440, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 15893.814948\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\ttraining's rmse: 8491.53\tvalid_1's rmse: 35374.7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 11440, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 16188.877185\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's rmse: 27741.7\tvalid_1's rmse: 31950.4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 11440, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 15158.723252\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's rmse: 12900.4\tvalid_1's rmse: 76768.4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 11440, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 15386.609178\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's rmse: 19539.4\tvalid_1's rmse: 44679.7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 99250\n",
      "[LightGBM] [Info] Number of data points in the train set: 14300, number of used features: 398\n",
      "[LightGBM] [Info] Start training from score 15685.366084\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 17433.7\tvalid_1's rmse: 35331.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/y.kotani/Desktop/study/youtube_predict_view_count/.venv/lib/python3.10/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
      "2023/12/17 23:35:11 WARNING mlflow.data.pandas_dataset: Failed to infer schema for Pandas dataset. Exception: Unable to map 'object' type to MLflow DataType. object can be mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\n",
      "2023/12/17 23:35:14 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/0n/ylqz1mkx0k34vl1stkkxb17h0000gq/T/tmplwfineox/model, flavor: lightgbm), fall back to return ['lightgbm==4.1.0']. Set logging level to DEBUG to see the full traceback.\n",
      "/Users/y.kotani/Desktop/study/youtube_predict_view_count/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'lgb_base_model' already exists. Creating a new version of this model...\n",
      "2023/12/17 23:35:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lgb_base_model, version 2\n",
      "Created version '2' of model 'lgb_base_model'.\n"
     ]
    }
   ],
   "source": [
    "training_pipeline = TraingingPipeline(\n",
    "    feature_extracted_df=feature_extraxted_data\n",
    ")\n",
    "training_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
